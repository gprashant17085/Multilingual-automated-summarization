{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Gigaword_summarization.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WzmVngU-xxWG","executionInfo":{"status":"ok","timestamp":1607123733179,"user_tz":300,"elapsed":25970,"user":{"displayName":"Prashant Garmella","photoUrl":"","userId":"16927257563044586479"}},"outputId":"b0b61fae-2372-4514-b7f7-f17223723bc4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UYtCJ10CyDbl","executionInfo":{"status":"ok","timestamp":1607123734860,"user_tz":300,"elapsed":308,"user":{"displayName":"Prashant Garmella","photoUrl":"","userId":"16927257563044586479"}},"outputId":"fa75acd3-5884-48c1-b802-57c59d5f088e"},"source":["cd '/content/drive/MyDrive/nlp_project'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/nlp_project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"icy31hhZyH3R","executionInfo":{"status":"ok","timestamp":1607123737634,"user_tz":300,"elapsed":310,"user":{"displayName":"Prashant Garmella","photoUrl":"","userId":"16927257563044586479"}},"outputId":"e0cfa992-f85e-4bdb-dc3c-6edecf38d4ec"},"source":["cd opennmt/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/nlp_project/opennmt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1kKGHZsyydWj","executionInfo":{"status":"ok","timestamp":1607123742933,"user_tz":300,"elapsed":4381,"user":{"displayName":"Prashant Garmella","photoUrl":"","userId":"16927257563044586479"}},"outputId":"fd0338d8-80c2-452c-8396-c07e7516632b"},"source":["!pip install configargparse"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting configargparse\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/79/3045743bb26ca2e44a1d317c37395462bfed82dbbd38e69a3280b63696ce/ConfigArgParse-1.2.3.tar.gz (42kB)\n","\r\u001b[K     |███████▊                        | 10kB 26.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 20kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 30kB 14.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 40kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n","\u001b[?25hBuilding wheels for collected packages: configargparse\n","  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configargparse: filename=ConfigArgParse-1.2.3-cp36-none-any.whl size=19329 sha256=b0c2b1261a19d9770910479d01cccb75e62620a475dc03b2dfaf8374834c2cc8\n","  Stored in directory: /root/.cache/pip/wheels/bd/d6/53/034032da9498bda2385cd50a51a289e88090b5da2d592b1fdf\n","Successfully built configargparse\n","Installing collected packages: configargparse\n","Successfully installed configargparse-1.2.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6InXst3gzxUY","executionInfo":{"status":"ok","timestamp":1607123934753,"user_tz":300,"elapsed":190274,"user":{"displayName":"Prashant Garmella","photoUrl":"","userId":"16927257563044586479"}},"outputId":"d74646de-7e4d-4dc9-ac6e-4e72828b2f16"},"source":["!pip install git+https://github.com/pytorch/text"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/pytorch/text\n","  Cloning https://github.com/pytorch/text to /tmp/pip-req-build-ri3cmoeo\n","  Running command git clone -q https://github.com/pytorch/text /tmp/pip-req-build-ri3cmoeo\n","  Running command git submodule update --init --recursive -q\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+ec413ff) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+ec413ff) (2.23.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+ec413ff) (1.7.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+ec413ff) (1.18.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+ec413ff) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+ec413ff) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+ec413ff) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+ec413ff) (2020.11.8)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.9.0a0+ec413ff) (0.8)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.9.0a0+ec413ff) (0.16.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.9.0a0+ec413ff) (3.7.4.3)\n","Building wheels for collected packages: torchtext\n","  Building wheel for torchtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchtext: filename=torchtext-0.9.0a0+ec413ff-cp36-cp36m-linux_x86_64.whl size=7049051 sha256=8f460aa6f662bfc270050c6bde031f62b56f3e50e7313d411bd2f6fdf63dbfbe\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-mkn4blf3/wheels/73/14/71/ed033fd999ae4933e17df3e91be2014e61c2f312a88a164ff5\n","Successfully built torchtext\n","Installing collected packages: torchtext\n","  Found existing installation: torchtext 0.3.1\n","    Uninstalling torchtext-0.3.1:\n","      Successfully uninstalled torchtext-0.3.1\n","Successfully installed torchtext-0.9.0a0+ec413ff\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hzN2QbFlyJgW","executionInfo":{"status":"ok","timestamp":1607120553380,"user_tz":300,"elapsed":402401,"user":{"displayName":"Prashant Garmella","photoUrl":"","userId":"16927257563044586479"}},"outputId":"b9501d65-bee6-46cd-f703-167ece4af0ae"},"source":["!python preprocess.py -train_src ./data/train/train.article.txt -train_tgt ./data/train/train.title.txt -valid_src ./data/train/valid.article.filter.txt -valid_tgt ./data/train/valid.title.filter.txt -save_data ./data/train/textsum"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-12-04 22:15:52,545 INFO] Extracting features...\n","[2020-12-04 22:15:52,578 INFO]  * number of source features: 0.\n","[2020-12-04 22:15:52,578 INFO]  * number of target features: 0.\n","[2020-12-04 22:15:52,578 INFO] Building `Fields` object...\n","/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n","/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:36: UserWarning: TextMultiField class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n","[2020-12-04 22:15:52,579 INFO] Building & saving training data...\n","[2020-12-04 22:15:55,878 INFO] Building shard 0.\n","/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:52: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n","[2020-12-04 22:16:50,439 INFO]  * saving 0th train data shard to ./data/train/textsum.train.0.pt.\n","tcmalloc: large alloc 1073741824 bytes == 0x66f20000 @  0x7f139856a1e7 0x5aca7b 0x4e0513 0x4e1dc0 0x4e23ab 0x4e2da4 0x4e2924 0x4e0df8 0x4e255b 0x4e23cf 0x4e29d0 0x4e0df8 0x4e255b 0x4e33c6 0x5eb562 0x50a1cc 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x588d41\n","[2020-12-04 22:17:34,388 INFO] Building shard 1.\n","[2020-12-04 22:18:31,918 INFO]  * saving 1th train data shard to ./data/train/textsum.train.1.pt.\n","[2020-12-04 22:19:16,604 INFO] Building shard 2.\n","[2020-12-04 22:20:12,173 INFO]  * saving 2th train data shard to ./data/train/textsum.train.2.pt.\n","[2020-12-04 22:20:53,175 INFO] Building shard 3.\n","[2020-12-04 22:21:38,525 INFO]  * saving 3th train data shard to ./data/train/textsum.train.3.pt.\n","[2020-12-04 22:22:12,666 INFO]  * tgt vocab size: 50004.\n","[2020-12-04 22:22:12,907 INFO]  * src vocab size: 50002.\n","[2020-12-04 22:22:13,457 INFO] Building & saving validation data...\n","[2020-12-04 22:22:18,038 INFO] Building shard 0.\n","/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:52: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n","[2020-12-04 22:22:24,423 INFO]  * saving 0th valid data shard to ./data/train/textsum.valid.0.pt.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GHkjQOGlzQyB","executionInfo":{"status":"ok","timestamp":1607119737904,"user_tz":300,"elapsed":419,"user":{"displayName":"Prashant Garmella","photoUrl":"","userId":"16927257563044586479"}},"outputId":"ea4c0fb5-9355-4540-8332-3f4c56040763"},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mavailable_models\u001b[0m/       floyd.yml                                 server.py\n","CHANGELOG.md            github_deploy_key_opennmt_opennmt_py.enc  setup.py\n","\u001b[01;34mconfig\u001b[0m/                 LICENSE.md                                \u001b[01;34mtools\u001b[0m/\n","CONTRIBUTING.md         \u001b[01;34monmt\u001b[0m/                                     train.py\n","\u001b[01;34mdata\u001b[0m/                   preprocess.py                             translate.py\n","\u001b[01;34mdocs\u001b[0m/                   README.md\n","floyd_requirements.txt  requirements.opt.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"leClPLoq52V4","executionInfo":{"status":"ok","timestamp":1607121466259,"user_tz":300,"elapsed":365,"user":{"displayName":"Prashant Garmella","photoUrl":"","userId":"16927257563044586479"}},"outputId":"d3f792c6-25e7-4694-bc2b-9e06479a9b56"},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mavailable_models\u001b[0m/       floyd.yml                                 server.py\n","CHANGELOG.md            github_deploy_key_opennmt_opennmt_py.enc  setup.py\n","\u001b[01;34mconfig\u001b[0m/                 LICENSE.md                                \u001b[01;34mtools\u001b[0m/\n","CONTRIBUTING.md         \u001b[01;34monmt\u001b[0m/                                     train.py\n","\u001b[01;34mdata\u001b[0m/                   preprocess.py                             translate.py\n","\u001b[01;34mdocs\u001b[0m/                   README.md\n","floyd_requirements.txt  requirements.opt.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AhnD4jkczRF0","executionInfo":{"status":"ok","timestamp":1607122464650,"user_tz":300,"elapsed":2743,"user":{"displayName":"Prashant Garmella","photoUrl":"","userId":"16927257563044586479"}},"outputId":"8dfbdd19-42f9-492d-c781-84001ab6b6ac"},"source":["!python -u train.py -data ./data/train/textsum -save_model textsum2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"train.py\", line 6, in <module>\n","    main()\n","  File \"/content/drive/My Drive/nlp_project/opennmt/onmt/bin/train.py\", line 197, in main\n","    train(opt)\n","  File \"/content/drive/My Drive/nlp_project/opennmt/onmt/bin/train.py\", line 63, in train\n","    train_iter = build_dataset_iter(shard_base, fields, opt)\n","  File \"/content/drive/My Drive/nlp_project/opennmt/onmt/inputters/inputter.py\", line 919, in build_dataset_iter\n","    key=lambda p: int(p.split(\".\")[-2])))\n","  File \"/content/drive/My Drive/nlp_project/opennmt/onmt/inputters/inputter.py\", line 919, in <lambda>\n","    key=lambda p: int(p.split(\".\")[-2])))\n","ValueError: invalid literal for int() with base 10: '0 (1)'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OVxgvxC793cG","executionInfo":{"status":"ok","timestamp":1607123704293,"user_tz":300,"elapsed":461,"user":{"displayName":"Prashant Garmella","photoUrl":"","userId":"16927257563044586479"}},"outputId":"6480f641-8284-4e55-ec33-233f8ef1d819"},"source":["!python ../opennmt/preprocess.py \\\n"," -train_src data/train/train.article.txt \\\n"," -train_tgt data/train/train.title.txt \\\n"," -valid_src data/train/valid.article.filter.txt \\\n"," -valid_tgt data/train/valid.title.filter.txt \\\n"," -save_data data/PREPROCESSED \\\n"," -src_seq_length 10000 \\\n"," -dynamic_dict \\\n"," -share_vocab "],"execution_count":null,"outputs":[{"output_type":"stream","text":["python3: can't open file '../opennmt/preprocess.py': [Errno 2] No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCzDZKrFBg2d","executionInfo":{"status":"ok","timestamp":1607123481271,"user_tz":300,"elapsed":322,"user":{"displayName":"Prashant Garmella","photoUrl":"","userId":"16927257563044586479"}},"outputId":"5cbce2dd-b671-4569-9372-7ef20737c0d8"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2TZuqzyhAAcn","executionInfo":{"status":"ok","timestamp":1607124201114,"user_tz":300,"elapsed":2115,"user":{"displayName":"Prashant Garmella","photoUrl":"","userId":"16927257563044586479"}},"outputId":"9c52063f-5c47-470e-9e16-0ec6f707711e"},"source":["!python -u ../opennmt/train.py \\\n"," -save_model data/models_v2/ \\\n"," -data data/train/textsum \\\n"," -global_attention mlp \\\n"," -word_vec_size 128 \\\n"," -rnn_size 512 \\\n"," -layers 2 \\\n"," -encoder_type brnn \\\n"," -train_steps 2000000 \\\n"," -report_every 100 \\\n"," -valid_steps 10000 \\\n"," -valid_batch_size 32 \\\n"," -max_generator_batches 128 \\\n"," -save_checkpoint_steps 10000 \\\n"," -max_grad_norm 2 \\\n"," -dropout 0.1 \\\n"," -batch_size 16 \\\n"," -optim adagrad \\\n"," -learning_rate 0.15 \\\n"," -start_decay_steps 100000 \\\n"," -decay_steps 50000 \\\n"," -adagrad_accumulator_init 0.1 \\\n"," -reuse_copy_attn \\\n"," -copy_loss_by_seqlength \\\n"," -bridge \\\n"," -seed 919 \\\n"," -gpu_ranks 0 \\\n"," -log_file train.v2.log"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"../opennmt/train.py\", line 6, in <module>\n","    main()\n","  File \"/content/drive/My Drive/nlp_project/opennmt/onmt/bin/train.py\", line 197, in main\n","    train(opt)\n","  File \"/content/drive/My Drive/nlp_project/opennmt/onmt/bin/train.py\", line 39, in train\n","    vocab = torch.load(opt.data + '.vocab.pt')\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 594, in load\n","    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 853, in _load\n","    result = unpickler.load()\n","  File \"/content/drive/My Drive/nlp_project/opennmt/onmt/inputters/inputter.py\", line 34, in _setstate\n","    def _setstate(self, state):\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IKhJuRM8EXSH"},"source":["!python translate.py -model textsum_acc_51.38_ppl_12.59_e13.pt -src ../data/Giga/input.txt -gpu 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0WBnAUBlEa7f"},"source":["cd ../files2rouge\n","!python files2rouge.py ../opennmt/pred.txt ../data/Giga/task1_ref0.txt"],"execution_count":null,"outputs":[]}]}