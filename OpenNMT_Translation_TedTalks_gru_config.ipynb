{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "OpenNMT_Translation_TedTalks_gru_config.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5doABIq2VScm",
        "outputId": "aa218157-cbff-4675-ba75-7a60bf84d1a3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-WIdtn36HrN"
      },
      "source": [
        "#!git clone -b legacy https://github.com/OpenNMT/OpenNMT-py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTUqY_y6Vtu4",
        "outputId": "05d3da6d-e231-410a-dc66-724b66427e03"
      },
      "source": [
        "cd drive/My Drive/NLP_Project_Personal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/NLP_Project_Personal'\n",
            "/content/drive/My Drive/NLP_Project_Personal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBS3FVmS6VaF"
      },
      "source": [
        "#!rm -rf /content/drive/MyDrive/NLP_Project_Personal/OpenNMT-py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLKAfAGnJot4",
        "outputId": "3c2b0ec3-42e2-4e05-81ef-3df1c44935d9"
      },
      "source": [
        "#!git clone https://github.com/OpenNMT/OpenNMT-py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'OpenNMT-py' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebrkfMjmR_8z",
        "outputId": "dddc7132-51ca-4c86-d675-457f170239d7"
      },
      "source": [
        "!pip install OpenNMT-py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: OpenNMT-py in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (2.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (4.41.1)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.2.3)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.1.2)\n",
            "Requirement already satisfied: pyonmttok==1.*; platform_system == \"Linux\" in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.22.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (0.16.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.7.0+cu101)\n",
            "Collecting torchtext==0.4.0\n",
            "  Using cached https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: waitress in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.4.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.35.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.33.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (3.3.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (50.3.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.7.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.18.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.17.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (3.12.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.4.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (2.11.2)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->OpenNMT-py) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->OpenNMT-py) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py) (2.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py) (3.1.0)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.9.0a0+d6d7f20\n",
            "    Uninstalling torchtext-0.9.0a0+d6d7f20:\n",
            "      Successfully uninstalled torchtext-0.9.0a0+d6d7f20\n",
            "Successfully installed torchtext-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z8fTg8PWNU-"
      },
      "source": [
        "#!cd /content/drive/MyDrive/NLP_Project_Personal/OpenNMT-py/requirements.opt.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyLkpZcJSPF_"
      },
      "source": [
        "#!pip install -r requirements.opt.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe_tiyjITbza",
        "outputId": "d934990b-9621-41ad-8775-8c0784461b03"
      },
      "source": [
        "!pip install configargparse\n",
        "!pip install torch==1.7.0\n",
        "!pip install git+https://github.com/pytorch/text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.6/dist-packages (1.2.3)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (1.18.5)\n",
            "Collecting git+https://github.com/pytorch/text\n",
            "  Cloning https://github.com/pytorch/text to /tmp/pip-req-build-aro3hpc_\n",
            "  Running command git clone -q https://github.com/pytorch/text /tmp/pip-req-build-aro3hpc_\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+d6d7f20) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+d6d7f20) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+d6d7f20) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+d6d7f20) (1.18.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+d6d7f20) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+d6d7f20) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+d6d7f20) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+d6d7f20) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.9.0a0+d6d7f20) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.9.0a0+d6d7f20) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.9.0a0+d6d7f20) (0.8)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchtext: filename=torchtext-0.9.0a0+d6d7f20-cp36-cp36m-linux_x86_64.whl size=7053953 sha256=f949d351797720937f1a81eee8be59a018f6549af2af9259b24061d6e6ff57cc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hph44hui/wheels/73/14/71/ed033fd999ae4933e17df3e91be2014e61c2f312a88a164ff5\n",
            "Successfully built torchtext\n",
            "\u001b[31mERROR: opennmt-py 1.2.0 has requirement torchtext==0.4.0, but you'll have torchtext 0.9.0a0+d6d7f20 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.4.0\n",
            "    Uninstalling torchtext-0.4.0:\n",
            "      Successfully uninstalled torchtext-0.4.0\n",
            "Successfully installed torchtext-0.9.0a0+d6d7f20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-veJKtCpvQen"
      },
      "source": [
        "# Read in the XML file\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "root_folder = \"/content/drive/MyDrive/DSGA_1011_NLP_Project/Data/TED_TALK_ES-EN /es-en/\"\n",
        "language = 'es'\n",
        "dataset = 'train'\n",
        "file = dataset+'.tags.es-en.'+language+'.xml'\n",
        "file_path = root_folder+file\n",
        "tree = ET.parse(file_path)\n",
        "root = tree.getroot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "l8UlTDxsvRQ1",
        "outputId": "2313031b-38e7-4a67-9cc9-a6838a3d8314"
      },
      "source": [
        "transcripts = []\n",
        "for child in root:\n",
        "  if child.tag == 'transcript':\n",
        "    transcripts.append(child.text)\n",
        "  #rows.append({\"talkids\": talk_id, \"transcripts\": transcript_id})\n",
        "transcripts_sentences = []\n",
        "for x in transcripts:\n",
        "  for a in x.split('\\n'):\n",
        "    transcripts_sentences.append(a)\n",
        "train_es = pd.DataFrame(transcripts_sentences, columns = ['es'])\n",
        "train_es.head(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>es</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>El océano puede ser una cosa muy complicada.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Y podria ser una cosa muy complicada lo que la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Y unirlas, podría ser una tarea desalentadora....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Esos temas sencillos no son realmente temas ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Cuantas personas han visto el letrero \" Playa ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Por que pasa ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Sucede porque hemos arruinado tanto la base de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Usualmente lo que se rebosa son las aguas resi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Cuantos de ustedes han ido a un parque estatal...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   es\n",
              "0                                                    \n",
              "1       El océano puede ser una cosa muy complicada. \n",
              "2   Y podria ser una cosa muy complicada lo que la...\n",
              "3   Y unirlas, podría ser una tarea desalentadora....\n",
              "4   Esos temas sencillos no son realmente temas ac...\n",
              "..                                                ...\n",
              "95  Cuantas personas han visto el letrero \" Playa ...\n",
              "96                                    Por que pasa ? \n",
              "97  Sucede porque hemos arruinado tanto la base de...\n",
              "98  Usualmente lo que se rebosa son las aguas resi...\n",
              "99  Cuantos de ustedes han ido a un parque estatal...\n",
              "\n",
              "[100 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUZm2MegvRYM"
      },
      "source": [
        "# Read in the XML file\n",
        "language = 'en'\n",
        "dataset = 'train'\n",
        "file = dataset+'.tags.es-en.'+language+'.xml'\n",
        "file_path = root_folder+file\n",
        "tree = ET.parse(file_path)\n",
        "root = tree.getroot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Y9Q0IiIwvRek",
        "outputId": "d9578298-53fb-4b43-8930-7236b61b743b"
      },
      "source": [
        "transcripts = []\n",
        "for child in root:\n",
        "  if child.tag == 'transcript':\n",
        "    transcripts.append(child.text)\n",
        "  #rows.append({\"talkids\": talk_id, \"transcripts\": transcript_id})\n",
        "transcripts_sentences = []\n",
        "for x in transcripts:\n",
        "  for a in x.split('\\n'):\n",
        "    transcripts_sentences.append(a)\n",
        "train_en = pd.DataFrame(transcripts_sentences, columns = ['en'])\n",
        "train_en.head(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It can be a very complicated thing, the ocean.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>And it can be a very complicated thing, what h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>And bringing those two together might seem a v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>And those simple themes aren't really themes a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>How many people have seen a \"beach closed\" sign?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Why does that happen?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>It happens because we have jammed so much into...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Often what jams us up is sewage.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Now how many of you have ever gone to a state ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   en\n",
              "0                                                    \n",
              "1     It can be a very complicated thing, the ocean. \n",
              "2   And it can be a very complicated thing, what h...\n",
              "3   And bringing those two together might seem a v...\n",
              "4   And those simple themes aren't really themes a...\n",
              "..                                                ...\n",
              "95  How many people have seen a \"beach closed\" sign? \n",
              "96                             Why does that happen? \n",
              "97  It happens because we have jammed so much into...\n",
              "98                  Often what jams us up is sewage. \n",
              "99  Now how many of you have ever gone to a state ...\n",
              "\n",
              "[100 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKVIbf81ZGzl"
      },
      "source": [
        "# Resource : https://machinelearningmastery.com/prepare-french-english-dataset-machine-translation/\n",
        "def clean_data(en_europarl, es_europarl):\n",
        "    remove = []\n",
        "    for i in range(len(es_europarl)-1):\n",
        "        en_sent = en_europarl.iloc[i][0]\n",
        "        es_sent = es_europarl.iloc[i][0]\n",
        "        if not any(word.isalpha() for word in en_sent):\n",
        "            remove.append(i)\n",
        "        elif not any(word.isalpha() for word in es_sent):\n",
        "            remove.append(i)\n",
        "    \n",
        "    for idx in reversed(remove): \n",
        "        en_europarl.drop(idx)\n",
        "        es_europarl.drop(idx)\n",
        "\n",
        "    return en_europarl, es_europarl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiSwQTzdP_eX"
      },
      "source": [
        "# remove = []\n",
        "# for i in range(len(train_en)):\n",
        "#     en_sent = train_en.iloc[i][0]\n",
        "#     es_sent = train_es.iloc[i][0]\n",
        "#     if not any(word.isalpha() for word in en_sent):\n",
        "#         remove.append(i)\n",
        "#     elif not any(word.isalpha() for word in es_sent):\n",
        "#         remove.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ffP6VAHQQai"
      },
      "source": [
        "# print(remove)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNoQ1I7-RIHs",
        "outputId": "589a328d-c622-44b6-e29b-d68096a03d8b"
      },
      "source": [
        "#print(len(train_es))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "154420\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNKephufRdnt",
        "outputId": "9df3ca06-3f0e-4c63-ae74-37f846db777b"
      },
      "source": [
        " #print(train_en.iloc[154279])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en    So this is just one example of a new era reall...\n",
            "Name: 154279, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZKKU-bvyS6f"
      },
      "source": [
        "train_en_cleaned, train_es_cleaned = clean_data(train_en, train_es)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVxs20GjDnQ"
      },
      "source": [
        "#train_en_cleaned_full = [sentence[1][0] for sentence in train_en_cleaned.iterrows() if len(sentence[1][0]) > 0]\n",
        "#train_es_cleaned_full = [sentence[1][0] for sentence in train_es_cleaned.iterrows() if len(sentence[1][0]) > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReUDgwmPyeES"
      },
      "source": [
        "train_en_cleaned_sample = train_en_cleaned[:100000]\n",
        "train_es_cleaned_sample = train_es_cleaned[:100000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUl2hQU80qYE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH7KNPz9yetL"
      },
      "source": [
        "# For future \n",
        "X_train, X_test, y_train, y_test = train_test_split(train_en_cleaned_sample, train_es_cleaned_sample, test_size=0.2, random_state=1)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "rq8amNmXEeER",
        "outputId": "a24f0a8a-65e9-4dab-f5c5-9e4e7659659e"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>es</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>78689</th>\n",
              "      <td>Y pienso que éste es realmente el origen de lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76423</th>\n",
              "      <td>Ahí esta el aparato parecido a un horno; Una v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86945</th>\n",
              "      <td>Mi mamá era un poco como una diseñadora también.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57427</th>\n",
              "      <td>Pero basta de teoría.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34616</th>\n",
              "      <td>Chica 3: Este es mi pretendiente.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      es\n",
              "78689  Y pienso que éste es realmente el origen de lo...\n",
              "76423  Ahí esta el aparato parecido a un horno; Una v...\n",
              "86945  Mi mamá era un poco como una diseñadora también. \n",
              "57427                             Pero basta de teoría. \n",
              "34616                 Chica 3: Este es mi pretendiente. "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRWxZgfZ1p2H"
      },
      "source": [
        "!cd /content/drive/MyDrive/NLP_Project_Personal/OpenNMT-py/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-UttwJ41vU3"
      },
      "source": [
        "path_to_data = '/content/drive/MyDrive/NLP_Project_Personal/OpenNMT-py/data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTOHKtfDkod6"
      },
      "source": [
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0_I169Myj8p"
      },
      "source": [
        "with open(path_to_data + 'tedtalksal_es_train.txt', 'w') as f: \n",
        "    for line in y_train.iterrows():\n",
        "      if len(line[1][0]) > 0:\n",
        "        f.write(line[1][0] + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6xuKKeL3stY"
      },
      "source": [
        "with open(path_to_data + 'tedtalksal_en_train.txt', 'w') as f: \n",
        "    for line in X_train.iterrows(): \n",
        "      if len(line[1][0]) > 0:\n",
        "        f.write(line[1][0] + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO9X8Rjh4Exo"
      },
      "source": [
        "with open(path_to_data + 'tedtalksal_es_val.txt', 'w') as f: \n",
        "    for line in y_val.iterrows(): \n",
        "      if len(line[1][0]) > 0:\n",
        "        f.write(line[1][0] + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhCMtGiZ4Feu"
      },
      "source": [
        "with open(path_to_data + 'tedtalksal_en_val.txt', 'w') as f: \n",
        "    for line in X_val.iterrows(): \n",
        "      if len(line[1][0]) > 0:\n",
        "        f.write(line[1][0] + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gjb3zeF4FSR"
      },
      "source": [
        "with open(path_to_data + 'tedtalksal_es_test.txt', 'w') as f: \n",
        "    for line in y_test.iterrows(): \n",
        "      if len(line[1][0]) > 0:\n",
        "        f.write(line[1][0] + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHCZdWBO4EnJ"
      },
      "source": [
        "writeable = [line[1][0] for line in X_test.iterrows() if len(line[1][0]) > 0 and line[1][0] not in string.whitespace]\n",
        "with open(path_to_data + 'tedtalksal_en_test.txt', 'w') as f: \n",
        "    for x in writeable:\n",
        "      f.write(x + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gLM2AfUkxVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0135e5-2e48-4c8f-d2c8-9fcf131aead1"
      },
      "source": [
        "writeable = [line[1][0] for line in y_train.iterrows() if len(line[1][0]) > 0 and line[1][0] != \" \"]\n",
        "with open(path_to_data + 'tedtalksal_es_train.txt', 'w') as f: \n",
        "    for x in writeable:\n",
        "      f.write(x + '\\n')\n",
        "print(len(writeable))\n",
        "\n",
        "writeable = [line[1][0] for line in X_train.iterrows() if len(line[1][0]) > 0 and line[1][0] != \" \"]\n",
        "with open(path_to_data + 'tedtalksal_en_train.txt', 'w') as f: \n",
        "    for x in writeable:\n",
        "      f.write(x + '\\n')\n",
        "print(len(writeable))\n",
        " \n",
        "writeable = [line[1][0] for line in X_test.iterrows() if len(line[1][0]) > 0 and line[1][0] != \" \"]\n",
        "with open(path_to_data + 'tedtalksal_en_test.txt', 'w') as f: \n",
        "    for x in writeable:\n",
        "      f.write(x + '\\n')\n",
        "print(len(writeable))\n",
        " \n",
        "writeable = [line[1][0] for line in y_val.iterrows() if len(line[1][0]) > 0 and line[1][0] != \" \"]\n",
        "with open(path_to_data + 'tedtalksal_es_val.txt', 'w') as f: \n",
        "    for x in writeable:\n",
        "      f.write(x + '\\n')\n",
        "print(len(writeable))\n",
        " \n",
        "writeable = [line[1][0] for line in X_val.iterrows() if len(line[1][0]) > 0 and line[1][0] != \" \"]\n",
        "with open(path_to_data + 'tedtalksal_en_val.txt', 'w') as f: \n",
        "    for x in writeable:\n",
        "      f.write(x + '\\n')\n",
        "print(len(writeable))\n",
        " \n",
        "writeable = [line[1][0] for line in y_test.iterrows() if len(line[1][0]) > 0 and line[1][0] != \" \"]\n",
        "with open(path_to_data + 'tedtalksal_es_test.txt', 'w') as f: \n",
        "    for x in writeable:\n",
        "      f.write(x + '\\n')\n",
        "print(len(writeable))\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78809\n",
            "78803\n",
            "9836\n",
            "9882\n",
            "9881\n",
            "9838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaKqhHdY57tE"
      },
      "source": [
        "!cd /content/drive/MyDrive/NLP_Project_Personal/OpenNMT-py/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbbuxxWLAJYw",
        "outputId": "4a48d04e-0b10-4682-dffd-3c1a752b11d6"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NLP_Project_Personal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTImYIdIyrxz",
        "outputId": "ac036304-beff-4a8c-d578-14e36cd718cd"
      },
      "source": [
        "!python OpenNMT-py/preprocess.py -overwrite -train_src OpenNMT-py/data/tedtalksal_es_train.txt -train_tgt OpenNMT-py/data/tedtalksal_en_train.txt -valid_src OpenNMT-py/data/tedtalksal_es_val.txt -valid_tgt OpenNMT-py/data/tedtalksal_en_val.txt -save_data OpenNMT-py/data/demo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-12-03 03:22:45,936 INFO] Extracting features...\n",
            "[2020-12-03 03:22:45,939 INFO]  * number of source features: 0.\n",
            "[2020-12-03 03:22:45,939 INFO]  * number of target features: 0.\n",
            "[2020-12-03 03:22:45,939 INFO] Building `Fields` object...\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:36: UserWarning: TextMultiField class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "[2020-12-03 03:22:45,939 INFO] Building & saving training data...\n",
            "[2020-12-03 03:22:45,940 WARNING] Shards for corpus train already exist, will be overwritten because `-overwrite` option is set.\n",
            "[2020-12-03 03:22:45,946 WARNING] Overwrite shards for corpus None\n",
            "multiprocessing.pool.RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/content/drive/MyDrive/NLP_Project_Personal/OpenNMT-py/onmt/bin/preprocess.py\", line 54, in process_one_shard\n",
            "    assert len(src_shard) == len(tgt_shard)\n",
            "AssertionError\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"OpenNMT-py/preprocess.py\", line 6, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/NLP_Project_Personal/OpenNMT-py/onmt/bin/preprocess.py\", line 318, in main\n",
            "    preprocess(opt)\n",
            "  File \"/content/drive/MyDrive/NLP_Project_Personal/OpenNMT-py/onmt/bin/preprocess.py\", line 298, in preprocess\n",
            "    'train', fields, src_reader, tgt_reader, align_reader, opt)\n",
            "  File \"/content/drive/MyDrive/NLP_Project_Personal/OpenNMT-py/onmt/bin/preprocess.py\", line 205, in build_save_dataset\n",
            "    for sub_counter in p.imap(func, shard_iter):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 735, in next\n",
            "    raise value\n",
            "AssertionError\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtJuKIVY8-Sv",
        "outputId": "010ab78a-48ae-4d1e-e31a-e74c781d1d57"
      },
      "source": [
        "# Change model name so don't overwrite previously saved models\n",
        "!python OpenNMT-py/train.py --gpu_ranks 0 -data OpenNMT-py/data/demo -save_model gru-model -rnn_type GRU -learning_rate 0.1 -train_steps 50000 -seed 42"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-12-03 02:21:35,008 INFO]  * src vocab size = 50002\n",
            "[2020-12-03 02:21:35,009 INFO]  * tgt vocab size = 50004\n",
            "[2020-12-03 02:21:35,009 INFO] Building model...\n",
            "[2020-12-03 02:21:46,624 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(50002, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (rnn): GRU(500, 500, num_layers=2, dropout=0.3)\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(50004, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): StackedGRU(\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): GRUCell(1000, 500)\n",
            "        (1): GRUCell(500, 500)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=500, out_features=500, bias=False)\n",
            "      (linear_out): Linear(in_features=1000, out_features=500, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=500, out_features=50004, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax(dim=-1)\n",
            "  )\n",
            ")\n",
            "[2020-12-03 02:21:46,624 INFO] encoder: 28007000\n",
            "[2020-12-03 02:21:46,624 INFO] decoder: 54560004\n",
            "[2020-12-03 02:21:46,624 INFO] * number of parameters: 82567004\n",
            "[2020-12-03 02:21:46,627 INFO] Starting training on GPU: [0]\n",
            "[2020-12-03 02:21:46,627 INFO] Start training loop and validate every 10000 steps...\n",
            "[2020-12-03 02:21:46,627 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2020-12-03 02:21:48,379 INFO] number of examples: 77039\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: OrderedIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "[2020-12-03 02:21:55,083 INFO] Step 50/50000; acc:   4.22; ppl: 9451.79; xent: 9.15; lr: 0.10000; 7237/7940 tok/s;      8 sec\n",
            "[2020-12-03 02:22:00,690 INFO] Step 100/50000; acc:   4.73; ppl: 4141.09; xent: 8.33; lr: 0.10000; 9994/10694 tok/s;     14 sec\n",
            "[2020-12-03 02:22:05,287 INFO] Step 150/50000; acc:   5.72; ppl: 2558.01; xent: 7.85; lr: 0.10000; 9970/11040 tok/s;     19 sec\n",
            "[2020-12-03 02:22:10,360 INFO] Step 200/50000; acc:   5.66; ppl: 3066.54; xent: 8.03; lr: 0.10000; 9591/10399 tok/s;     24 sec\n",
            "[2020-12-03 02:22:14,923 INFO] Step 250/50000; acc:   5.99; ppl: 2029.16; xent: 7.62; lr: 0.10000; 9720/10907 tok/s;     28 sec\n",
            "[2020-12-03 02:22:20,620 INFO] Step 300/50000; acc:   5.40; ppl: 2287.00; xent: 7.73; lr: 0.10000; 9983/10801 tok/s;     34 sec\n",
            "[2020-12-03 02:22:25,896 INFO] Step 350/50000; acc:   6.18; ppl: 1998.09; xent: 7.60; lr: 0.10000; 9509/10562 tok/s;     39 sec\n",
            "[2020-12-03 02:22:30,608 INFO] Step 400/50000; acc:   6.47; ppl: 1976.00; xent: 7.59; lr: 0.10000; 9682/10307 tok/s;     44 sec\n",
            "[2020-12-03 02:22:36,020 INFO] Step 450/50000; acc:   6.26; ppl: 1613.57; xent: 7.39; lr: 0.10000; 9307/10376 tok/s;     49 sec\n",
            "[2020-12-03 02:22:41,237 INFO] Step 500/50000; acc:   6.51; ppl: 1544.04; xent: 7.34; lr: 0.10000; 9469/10444 tok/s;     55 sec\n",
            "[2020-12-03 02:22:46,027 INFO] Step 550/50000; acc:   7.28; ppl: 1597.83; xent: 7.38; lr: 0.10000; 9241/10231 tok/s;     59 sec\n",
            "[2020-12-03 02:22:50,820 INFO] Step 600/50000; acc:   8.09; ppl: 1653.67; xent: 7.41; lr: 0.10000; 9316/10469 tok/s;     64 sec\n",
            "[2020-12-03 02:22:55,113 INFO] Step 650/50000; acc:   9.34; ppl: 1369.30; xent: 7.22; lr: 0.10000; 9146/9845 tok/s;     68 sec\n",
            "[2020-12-03 02:23:00,534 INFO] Step 700/50000; acc:   7.53; ppl: 1467.05; xent: 7.29; lr: 0.10000; 9665/10538 tok/s;     74 sec\n",
            "[2020-12-03 02:23:05,475 INFO] Step 750/50000; acc:   8.62; ppl: 1340.18; xent: 7.20; lr: 0.10000; 9288/10284 tok/s;     79 sec\n",
            "[2020-12-03 02:23:11,024 INFO] Step 800/50000; acc:   8.26; ppl: 1261.45; xent: 7.14; lr: 0.10000; 9558/10560 tok/s;     84 sec\n",
            "[2020-12-03 02:23:16,002 INFO] Step 850/50000; acc:   8.87; ppl: 1222.97; xent: 7.11; lr: 0.10000; 9084/10133 tok/s;     89 sec\n",
            "[2020-12-03 02:23:21,239 INFO] Step 900/50000; acc:   9.53; ppl: 1227.12; xent: 7.11; lr: 0.10000; 9361/10330 tok/s;     95 sec\n",
            "[2020-12-03 02:23:26,527 INFO] Step 950/50000; acc:   8.81; ppl: 1283.63; xent: 7.16; lr: 0.10000; 9392/10319 tok/s;    100 sec\n",
            "[2020-12-03 02:23:31,720 INFO] Step 1000/50000; acc:   8.96; ppl: 1154.17; xent: 7.05; lr: 0.10000; 8676/10039 tok/s;    105 sec\n",
            "[2020-12-03 02:23:37,189 INFO] Step 1050/50000; acc:   8.97; ppl: 1110.86; xent: 7.01; lr: 0.10000; 8968/10195 tok/s;    111 sec\n",
            "[2020-12-03 02:23:42,703 INFO] Step 1100/50000; acc:   9.43; ppl: 1073.15; xent: 6.98; lr: 0.10000; 9151/10421 tok/s;    116 sec\n",
            "[2020-12-03 02:23:48,337 INFO] Step 1150/50000; acc:   9.58; ppl: 1176.27; xent: 7.07; lr: 0.10000; 9168/10291 tok/s;    122 sec\n",
            "[2020-12-03 02:23:53,253 INFO] Step 1200/50000; acc:  10.47; ppl: 1142.70; xent: 7.04; lr: 0.10000; 9212/9927 tok/s;    127 sec\n",
            "[2020-12-03 02:23:53,856 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2020-12-03 02:23:56,020 INFO] number of examples: 77039\n",
            "[2020-12-03 02:24:02,790 INFO] Step 1250/50000; acc:   8.21; ppl: 1154.30; xent: 7.05; lr: 0.10000; 6739/7352 tok/s;    136 sec\n",
            "[2020-12-03 02:24:08,783 INFO] Step 1300/50000; acc:  10.02; ppl: 1102.61; xent: 7.01; lr: 0.10000; 9489/10123 tok/s;    142 sec\n",
            "[2020-12-03 02:24:13,677 INFO] Step 1350/50000; acc:  11.44; ppl: 975.19; xent: 6.88; lr: 0.10000; 9168/10137 tok/s;    147 sec\n",
            "[2020-12-03 02:24:19,181 INFO] Step 1400/50000; acc:  10.71; ppl: 996.26; xent: 6.90; lr: 0.10000; 8840/9685 tok/s;    153 sec\n",
            "[2020-12-03 02:24:23,995 INFO] Step 1450/50000; acc:  12.07; ppl: 894.72; xent: 6.80; lr: 0.10000; 8908/10054 tok/s;    157 sec\n",
            "[2020-12-03 02:24:30,178 INFO] Step 1500/50000; acc:  10.33; ppl: 1026.71; xent: 6.93; lr: 0.10000; 9508/10184 tok/s;    164 sec\n",
            "[2020-12-03 02:24:35,809 INFO] Step 1550/50000; acc:  11.22; ppl: 904.75; xent: 6.81; lr: 0.10000; 8841/9864 tok/s;    169 sec\n",
            "[2020-12-03 02:24:40,864 INFO] Step 1600/50000; acc:  11.52; ppl: 956.49; xent: 6.86; lr: 0.10000; 8987/9524 tok/s;    174 sec\n",
            "[2020-12-03 02:24:46,522 INFO] Step 1650/50000; acc:  11.10; ppl: 884.25; xent: 6.78; lr: 0.10000; 8619/9703 tok/s;    180 sec\n",
            "[2020-12-03 02:24:52,262 INFO] Step 1700/50000; acc:  11.26; ppl: 903.60; xent: 6.81; lr: 0.10000; 8885/9739 tok/s;    186 sec\n",
            "[2020-12-03 02:24:57,288 INFO] Step 1750/50000; acc:  12.53; ppl: 837.15; xent: 6.73; lr: 0.10000; 8502/9465 tok/s;    191 sec\n",
            "[2020-12-03 02:25:02,657 INFO] Step 1800/50000; acc:  12.45; ppl: 877.35; xent: 6.78; lr: 0.10000; 8746/9732 tok/s;    196 sec\n",
            "[2020-12-03 02:25:07,268 INFO] Step 1850/50000; acc:  13.41; ppl: 801.08; xent: 6.69; lr: 0.10000; 8599/9351 tok/s;    201 sec\n",
            "[2020-12-03 02:25:12,867 INFO] Step 1900/50000; acc:  12.24; ppl: 855.38; xent: 6.75; lr: 0.10000; 9026/9740 tok/s;    206 sec\n",
            "[2020-12-03 02:25:18,202 INFO] Step 1950/50000; acc:  12.88; ppl: 752.20; xent: 6.62; lr: 0.10000; 8578/9526 tok/s;    212 sec\n",
            "[2020-12-03 02:25:24,088 INFO] Step 2000/50000; acc:  12.19; ppl: 753.49; xent: 6.62; lr: 0.10000; 8825/9833 tok/s;    217 sec\n",
            "[2020-12-03 02:25:29,586 INFO] Step 2050/50000; acc:  12.09; ppl: 777.29; xent: 6.66; lr: 0.10000; 8703/9713 tok/s;    223 sec\n",
            "[2020-12-03 02:25:34,808 INFO] Step 2100/50000; acc:  12.60; ppl: 779.22; xent: 6.66; lr: 0.10000; 9020/9787 tok/s;    228 sec\n",
            "[2020-12-03 02:25:40,582 INFO] Step 2150/50000; acc:  11.37; ppl: 826.44; xent: 6.72; lr: 0.10000; 8967/9880 tok/s;    234 sec\n",
            "[2020-12-03 02:25:45,609 INFO] Step 2200/50000; acc:  13.24; ppl: 704.75; xent: 6.56; lr: 0.10000; 8185/9560 tok/s;    239 sec\n",
            "[2020-12-03 02:25:51,612 INFO] Step 2250/50000; acc:  12.12; ppl: 745.05; xent: 6.61; lr: 0.10000; 8804/9948 tok/s;    245 sec\n",
            "[2020-12-03 02:25:57,320 INFO] Step 2300/50000; acc:  12.68; ppl: 707.52; xent: 6.56; lr: 0.10000; 8634/9867 tok/s;    251 sec\n",
            "[2020-12-03 02:26:03,032 INFO] Step 2350/50000; acc:  13.23; ppl: 728.33; xent: 6.59; lr: 0.10000; 8875/9917 tok/s;    256 sec\n",
            "[2020-12-03 02:26:08,252 INFO] Step 2400/50000; acc:  13.25; ppl: 747.27; xent: 6.62; lr: 0.10000; 8896/9634 tok/s;    262 sec\n",
            "[2020-12-03 02:26:09,298 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2020-12-03 02:26:11,123 INFO] number of examples: 77039\n",
            "[2020-12-03 02:26:17,562 INFO] Step 2450/50000; acc:  10.44; ppl: 840.37; xent: 6.73; lr: 0.10000; 6841/7486 tok/s;    271 sec\n",
            "[2020-12-03 02:26:23,697 INFO] Step 2500/50000; acc:  12.40; ppl: 722.80; xent: 6.58; lr: 0.10000; 9127/9803 tok/s;    277 sec\n",
            "[2020-12-03 02:26:28,848 INFO] Step 2550/50000; acc:  14.35; ppl: 669.93; xent: 6.51; lr: 0.10000; 9077/9901 tok/s;    282 sec\n",
            "[2020-12-03 02:26:34,451 INFO] Step 2600/50000; acc:  13.46; ppl: 690.33; xent: 6.54; lr: 0.10000; 8525/9402 tok/s;    288 sec\n",
            "[2020-12-03 02:26:39,492 INFO] Step 2650/50000; acc:  15.57; ppl: 583.74; xent: 6.37; lr: 0.10000; 8798/9863 tok/s;    293 sec\n",
            "[2020-12-03 02:26:45,756 INFO] Step 2700/50000; acc:  13.64; ppl: 663.60; xent: 6.50; lr: 0.10000; 9264/9935 tok/s;    299 sec\n",
            "[2020-12-03 02:26:51,211 INFO] Step 2750/50000; acc:  14.63; ppl: 627.86; xent: 6.44; lr: 0.10000; 8680/9759 tok/s;    305 sec\n",
            "[2020-12-03 02:26:56,594 INFO] Step 2800/50000; acc:  14.63; ppl: 658.13; xent: 6.49; lr: 0.10000; 8985/9538 tok/s;    310 sec\n",
            "[2020-12-03 02:27:02,236 INFO] Step 2850/50000; acc:  14.79; ppl: 584.53; xent: 6.37; lr: 0.10000; 8667/9686 tok/s;    316 sec\n",
            "[2020-12-03 02:27:07,891 INFO] Step 2900/50000; acc:  14.25; ppl: 587.64; xent: 6.38; lr: 0.10000; 8882/9756 tok/s;    321 sec\n",
            "[2020-12-03 02:27:12,723 INFO] Step 2950/50000; acc:  15.83; ppl: 534.53; xent: 6.28; lr: 0.10000; 8539/9499 tok/s;    326 sec\n",
            "[2020-12-03 02:27:18,190 INFO] Step 3000/50000; acc:  15.41; ppl: 579.57; xent: 6.36; lr: 0.10000; 8974/9900 tok/s;    332 sec\n",
            "[2020-12-03 02:27:22,895 INFO] Step 3050/50000; acc:  16.49; ppl: 544.31; xent: 6.30; lr: 0.10000; 8414/9271 tok/s;    336 sec\n",
            "[2020-12-03 02:27:28,574 INFO] Step 3100/50000; acc:  15.71; ppl: 575.65; xent: 6.36; lr: 0.10000; 9034/9768 tok/s;    342 sec\n",
            "[2020-12-03 02:27:33,749 INFO] Step 3150/50000; acc:  16.62; ppl: 495.95; xent: 6.21; lr: 0.10000; 8473/9511 tok/s;    347 sec\n",
            "[2020-12-03 02:27:39,615 INFO] Step 3200/50000; acc:  15.84; ppl: 538.67; xent: 6.29; lr: 0.10000; 9040/9905 tok/s;    353 sec\n",
            "[2020-12-03 02:27:44,766 INFO] Step 3250/50000; acc:  16.42; ppl: 516.07; xent: 6.25; lr: 0.10000; 8765/9725 tok/s;    358 sec\n",
            "[2020-12-03 02:27:50,496 INFO] Step 3300/50000; acc:  16.09; ppl: 518.43; xent: 6.25; lr: 0.10000; 8815/9643 tok/s;    364 sec\n",
            "[2020-12-03 02:27:56,060 INFO] Step 3350/50000; acc:  16.24; ppl: 517.15; xent: 6.25; lr: 0.10000; 8799/9689 tok/s;    369 sec\n",
            "[2020-12-03 02:28:01,358 INFO] Step 3400/50000; acc:  17.21; ppl: 456.56; xent: 6.12; lr: 0.10000; 8191/9572 tok/s;    375 sec\n",
            "[2020-12-03 02:28:07,278 INFO] Step 3450/50000; acc:  16.98; ppl: 465.19; xent: 6.14; lr: 0.10000; 8601/9792 tok/s;    381 sec\n",
            "[2020-12-03 02:28:13,178 INFO] Step 3500/50000; acc:  17.45; ppl: 454.87; xent: 6.12; lr: 0.10000; 8841/9932 tok/s;    387 sec\n",
            "[2020-12-03 02:28:18,846 INFO] Step 3550/50000; acc:  17.67; ppl: 448.36; xent: 6.11; lr: 0.10000; 8628/9774 tok/s;    392 sec\n",
            "[2020-12-03 02:28:24,148 INFO] Step 3600/50000; acc:  18.77; ppl: 443.96; xent: 6.10; lr: 0.10000; 8867/9682 tok/s;    398 sec\n",
            "[2020-12-03 02:28:25,548 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2020-12-03 02:28:27,694 INFO] number of examples: 77039\n",
            "[2020-12-03 02:28:33,713 INFO] Step 3650/50000; acc:  15.45; ppl: 531.33; xent: 6.28; lr: 0.10000; 6579/7137 tok/s;    407 sec\n",
            "[2020-12-03 02:28:39,934 INFO] Step 3700/50000; acc:  17.55; ppl: 467.52; xent: 6.15; lr: 0.10000; 9227/9794 tok/s;    413 sec\n",
            "[2020-12-03 02:28:45,154 INFO] Step 3750/50000; acc:  20.19; ppl: 397.90; xent: 5.99; lr: 0.10000; 8946/9928 tok/s;    419 sec\n",
            "[2020-12-03 02:28:50,622 INFO] Step 3800/50000; acc:  19.35; ppl: 424.38; xent: 6.05; lr: 0.10000; 8594/9363 tok/s;    424 sec\n",
            "[2020-12-03 02:28:55,844 INFO] Step 3850/50000; acc:  21.30; ppl: 360.98; xent: 5.89; lr: 0.10000; 8874/9986 tok/s;    429 sec\n",
            "[2020-12-03 02:29:01,914 INFO] Step 3900/50000; acc:  19.46; ppl: 397.81; xent: 5.99; lr: 0.10000; 9105/9897 tok/s;    435 sec\n",
            "[2020-12-03 02:29:07,302 INFO] Step 3950/50000; acc:  20.17; ppl: 389.56; xent: 5.97; lr: 0.10000; 8670/9622 tok/s;    441 sec\n",
            "[2020-12-03 02:29:12,715 INFO] Step 4000/50000; acc:  19.91; ppl: 401.64; xent: 6.00; lr: 0.10000; 8900/9523 tok/s;    446 sec\n",
            "[2020-12-03 02:29:18,258 INFO] Step 4050/50000; acc:  20.38; ppl: 358.79; xent: 5.88; lr: 0.10000; 8704/9672 tok/s;    452 sec\n",
            "[2020-12-03 02:29:24,174 INFO] Step 4100/50000; acc:  19.92; ppl: 389.49; xent: 5.96; lr: 0.10000; 8936/9665 tok/s;    458 sec\n",
            "[2020-12-03 02:29:29,137 INFO] Step 4150/50000; acc:  22.08; ppl: 314.10; xent: 5.75; lr: 0.10000; 8211/9334 tok/s;    463 sec\n",
            "[2020-12-03 02:29:34,643 INFO] Step 4200/50000; acc:  21.21; ppl: 360.85; xent: 5.89; lr: 0.10000; 9004/9871 tok/s;    468 sec\n",
            "[2020-12-03 02:29:39,285 INFO] Step 4250/50000; acc:  22.56; ppl: 312.46; xent: 5.74; lr: 0.10000; 8537/9456 tok/s;    473 sec\n",
            "[2020-12-03 02:29:44,694 INFO] Step 4300/50000; acc:  22.13; ppl: 344.83; xent: 5.84; lr: 0.10000; 8944/9721 tok/s;    478 sec\n",
            "[2020-12-03 02:29:50,216 INFO] Step 4350/50000; acc:  22.24; ppl: 315.73; xent: 5.75; lr: 0.10000; 8751/9722 tok/s;    484 sec\n",
            "[2020-12-03 02:29:55,820 INFO] Step 4400/50000; acc:  22.17; ppl: 315.76; xent: 5.75; lr: 0.10000; 8962/9775 tok/s;    489 sec\n",
            "[2020-12-03 02:30:00,999 INFO] Step 4450/50000; acc:  22.70; ppl: 310.12; xent: 5.74; lr: 0.10000; 8755/9819 tok/s;    494 sec\n",
            "[2020-12-03 02:30:06,582 INFO] Step 4500/50000; acc:  22.17; ppl: 319.20; xent: 5.77; lr: 0.10000; 8967/9800 tok/s;    500 sec\n",
            "[2020-12-03 02:30:12,297 INFO] Step 4550/50000; acc:  21.78; ppl: 319.92; xent: 5.77; lr: 0.10000; 8789/9670 tok/s;    506 sec\n",
            "[2020-12-03 02:30:17,545 INFO] Step 4600/50000; acc:  22.89; ppl: 295.67; xent: 5.69; lr: 0.10000; 8219/9472 tok/s;    511 sec\n",
            "[2020-12-03 02:30:23,409 INFO] Step 4650/50000; acc:  22.38; ppl: 288.49; xent: 5.66; lr: 0.10000; 8619/9804 tok/s;    517 sec\n",
            "[2020-12-03 02:30:29,263 INFO] Step 4700/50000; acc:  22.98; ppl: 281.39; xent: 5.64; lr: 0.10000; 8757/9978 tok/s;    523 sec\n",
            "[2020-12-03 02:30:35,074 INFO] Step 4750/50000; acc:  22.62; ppl: 301.06; xent: 5.71; lr: 0.10000; 8538/9689 tok/s;    528 sec\n",
            "[2020-12-03 02:30:40,318 INFO] Step 4800/50000; acc:  24.39; ppl: 279.23; xent: 5.63; lr: 0.10000; 8904/9649 tok/s;    534 sec\n",
            "[2020-12-03 02:30:42,175 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2020-12-03 02:30:44,331 INFO] number of examples: 77039\n",
            "[2020-12-03 02:30:49,769 INFO] Step 4850/50000; acc:  20.73; ppl: 347.03; xent: 5.85; lr: 0.10000; 6516/7067 tok/s;    543 sec\n",
            "[2020-12-03 02:30:56,203 INFO] Step 4900/50000; acc:  21.81; ppl: 325.50; xent: 5.79; lr: 0.10000; 9171/9755 tok/s;    550 sec\n",
            "[2020-12-03 02:31:01,472 INFO] Step 4950/50000; acc:  25.65; ppl: 256.37; xent: 5.55; lr: 0.10000; 8849/9844 tok/s;    555 sec\n",
            "[2020-12-03 02:31:07,077 INFO] Step 5000/50000; acc:  24.25; ppl: 280.18; xent: 5.64; lr: 0.10000; 8758/9516 tok/s;    560 sec\n",
            "[2020-12-03 02:31:07,606 INFO] Saving checkpoint gru-model_step_5000.pt\n",
            "[2020-12-03 02:31:16,576 INFO] Step 5050/50000; acc:  26.19; ppl: 244.77; xent: 5.50; lr: 0.10000; 4887/5469 tok/s;    570 sec\n",
            "[2020-12-03 02:31:22,268 INFO] Step 5100/50000; acc:  25.63; ppl: 245.85; xent: 5.50; lr: 0.10000; 8688/9588 tok/s;    576 sec\n",
            "[2020-12-03 02:31:28,106 INFO] Step 5150/50000; acc:  24.09; ppl: 273.60; xent: 5.61; lr: 0.10000; 8670/9590 tok/s;    581 sec\n",
            "[2020-12-03 02:31:33,541 INFO] Step 5200/50000; acc:  24.94; ppl: 270.40; xent: 5.60; lr: 0.10000; 8805/9383 tok/s;    587 sec\n",
            "[2020-12-03 02:31:39,190 INFO] Step 5250/50000; acc:  24.95; ppl: 249.26; xent: 5.52; lr: 0.10000; 8596/9572 tok/s;    593 sec\n",
            "[2020-12-03 02:31:45,177 INFO] Step 5300/50000; acc:  25.22; ppl: 260.86; xent: 5.56; lr: 0.10000; 8896/9574 tok/s;    599 sec\n",
            "[2020-12-03 02:31:50,068 INFO] Step 5350/50000; acc:  26.68; ppl: 218.90; xent: 5.39; lr: 0.10000; 8332/9428 tok/s;    603 sec\n",
            "[2020-12-03 02:31:55,768 INFO] Step 5400/50000; acc:  25.92; ppl: 248.97; xent: 5.52; lr: 0.10000; 9069/9924 tok/s;    609 sec\n",
            "[2020-12-03 02:32:00,304 INFO] Step 5450/50000; acc:  27.64; ppl: 211.27; xent: 5.35; lr: 0.10000; 8370/9431 tok/s;    614 sec\n",
            "[2020-12-03 02:32:05,845 INFO] Step 5500/50000; acc:  26.75; ppl: 239.11; xent: 5.48; lr: 0.10000; 9077/9775 tok/s;    619 sec\n",
            "[2020-12-03 02:32:11,116 INFO] Step 5550/50000; acc:  27.41; ppl: 217.44; xent: 5.38; lr: 0.10000; 8682/9581 tok/s;    624 sec\n",
            "[2020-12-03 02:32:16,574 INFO] Step 5600/50000; acc:  27.57; ppl: 210.92; xent: 5.35; lr: 0.10000; 8930/9897 tok/s;    630 sec\n",
            "[2020-12-03 02:32:21,618 INFO] Step 5650/50000; acc:  27.58; ppl: 214.56; xent: 5.37; lr: 0.10000; 8807/9810 tok/s;    635 sec\n",
            "[2020-12-03 02:32:27,432 INFO] Step 5700/50000; acc:  26.23; ppl: 229.34; xent: 5.44; lr: 0.10000; 8923/9806 tok/s;    641 sec\n",
            "[2020-12-03 02:32:32,808 INFO] Step 5750/50000; acc:  27.25; ppl: 216.36; xent: 5.38; lr: 0.10000; 8736/9641 tok/s;    646 sec\n",
            "[2020-12-03 02:32:38,413 INFO] Step 5800/50000; acc:  26.85; ppl: 213.85; xent: 5.37; lr: 0.10000; 8347/9601 tok/s;    652 sec\n",
            "[2020-12-03 02:32:44,168 INFO] Step 5850/50000; acc:  26.94; ppl: 201.75; xent: 5.31; lr: 0.10000; 8585/9841 tok/s;    658 sec\n",
            "[2020-12-03 02:32:49,835 INFO] Step 5900/50000; acc:  27.50; ppl: 203.04; xent: 5.31; lr: 0.10000; 8722/9883 tok/s;    663 sec\n",
            "[2020-12-03 02:32:55,893 INFO] Step 5950/50000; acc:  26.29; ppl: 226.66; xent: 5.42; lr: 0.10000; 8596/9643 tok/s;    669 sec\n",
            "[2020-12-03 02:33:01,271 INFO] Step 6000/50000; acc:  28.50; ppl: 199.77; xent: 5.30; lr: 0.10000; 8967/9723 tok/s;    675 sec\n",
            "[2020-12-03 02:33:03,483 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2020-12-03 02:33:05,786 INFO] number of examples: 77039\n",
            "[2020-12-03 02:33:10,514 INFO] Step 6050/50000; acc:  25.67; ppl: 243.01; xent: 5.49; lr: 0.10000; 6302/6871 tok/s;    684 sec\n",
            "[2020-12-03 02:33:17,142 INFO] Step 6100/50000; acc:  25.35; ppl: 242.82; xent: 5.49; lr: 0.10000; 9135/9754 tok/s;    691 sec\n",
            "[2020-12-03 02:33:22,428 INFO] Step 6150/50000; acc:  29.55; ppl: 191.27; xent: 5.25; lr: 0.10000; 9014/9862 tok/s;    696 sec\n",
            "[2020-12-03 02:33:28,153 INFO] Step 6200/50000; acc:  28.17; ppl: 206.94; xent: 5.33; lr: 0.10000; 8754/9505 tok/s;    702 sec\n",
            "[2020-12-03 02:33:33,407 INFO] Step 6250/50000; acc:  30.18; ppl: 175.74; xent: 5.17; lr: 0.10000; 8849/9909 tok/s;    707 sec\n",
            "[2020-12-03 02:33:38,885 INFO] Step 6300/50000; acc:  28.95; ppl: 186.30; xent: 5.23; lr: 0.10000; 8852/9806 tok/s;    712 sec\n",
            "[2020-12-03 02:33:44,690 INFO] Step 6350/50000; acc:  28.25; ppl: 197.13; xent: 5.28; lr: 0.10000; 8751/9705 tok/s;    718 sec\n",
            "[2020-12-03 02:33:50,068 INFO] Step 6400/50000; acc:  28.87; ppl: 196.78; xent: 5.28; lr: 0.10000; 8826/9500 tok/s;    723 sec\n",
            "[2020-12-03 02:33:55,468 INFO] Step 6450/50000; acc:  28.86; ppl: 188.53; xent: 5.24; lr: 0.10000; 8875/9752 tok/s;    729 sec\n",
            "[2020-12-03 02:34:01,389 INFO] Step 6500/50000; acc:  29.04; ppl: 189.34; xent: 5.24; lr: 0.10000; 8853/9641 tok/s;    735 sec\n",
            "[2020-12-03 02:34:06,474 INFO] Step 6550/50000; acc:  30.00; ppl: 170.67; xent: 5.14; lr: 0.10000; 8562/9548 tok/s;    740 sec\n",
            "[2020-12-03 02:34:12,253 INFO] Step 6600/50000; acc:  29.55; ppl: 186.43; xent: 5.23; lr: 0.10000; 8895/9746 tok/s;    746 sec\n",
            "[2020-12-03 02:34:16,690 INFO] Step 6650/50000; acc:  31.18; ppl: 156.74; xent: 5.05; lr: 0.10000; 8109/9256 tok/s;    750 sec\n",
            "[2020-12-03 02:34:22,388 INFO] Step 6700/50000; acc:  30.09; ppl: 184.56; xent: 5.22; lr: 0.10000; 9108/9710 tok/s;    756 sec\n",
            "[2020-12-03 02:34:27,519 INFO] Step 6750/50000; acc:  30.89; ppl: 164.47; xent: 5.10; lr: 0.10000; 8582/9551 tok/s;    761 sec\n",
            "[2020-12-03 02:34:32,938 INFO] Step 6800/50000; acc:  30.98; ppl: 159.28; xent: 5.07; lr: 0.10000; 8925/9856 tok/s;    766 sec\n",
            "[2020-12-03 02:34:38,242 INFO] Step 6850/50000; acc:  30.35; ppl: 170.59; xent: 5.14; lr: 0.10000; 8918/9913 tok/s;    772 sec\n",
            "[2020-12-03 02:34:43,812 INFO] Step 6900/50000; acc:  30.27; ppl: 166.18; xent: 5.11; lr: 0.10000; 8923/9829 tok/s;    777 sec\n",
            "[2020-12-03 02:34:49,313 INFO] Step 6950/50000; acc:  30.38; ppl: 169.04; xent: 5.13; lr: 0.10000; 8771/9669 tok/s;    783 sec\n",
            "[2020-12-03 02:34:54,917 INFO] Step 7000/50000; acc:  30.41; ppl: 160.26; xent: 5.08; lr: 0.10000; 8303/9519 tok/s;    788 sec\n",
            "[2020-12-03 02:35:00,431 INFO] Step 7050/50000; acc:  30.52; ppl: 150.06; xent: 5.01; lr: 0.10000; 8542/9867 tok/s;    794 sec\n",
            "[2020-12-03 02:35:06,296 INFO] Step 7100/50000; acc:  30.38; ppl: 159.99; xent: 5.08; lr: 0.10000; 8689/9799 tok/s;    800 sec\n",
            "[2020-12-03 02:35:12,331 INFO] Step 7150/50000; acc:  29.63; ppl: 172.95; xent: 5.15; lr: 0.10000; 8680/9704 tok/s;    806 sec\n",
            "[2020-12-03 02:35:17,752 INFO] Step 7200/50000; acc:  31.55; ppl: 153.85; xent: 5.04; lr: 0.10000; 8908/9765 tok/s;    811 sec\n",
            "[2020-12-03 02:35:20,335 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2020-12-03 02:35:22,318 INFO] number of examples: 77039\n",
            "[2020-12-03 02:35:26,615 INFO] Step 7250/50000; acc:  29.04; ppl: 186.60; xent: 5.23; lr: 0.10000; 6529/7085 tok/s;    820 sec\n",
            "[2020-12-03 02:35:33,020 INFO] Step 7300/50000; acc:  28.71; ppl: 185.99; xent: 5.23; lr: 0.10000; 9014/9740 tok/s;    826 sec\n",
            "[2020-12-03 02:35:38,574 INFO] Step 7350/50000; acc:  32.08; ppl: 158.54; xent: 5.07; lr: 0.10000; 9040/9763 tok/s;    832 sec\n",
            "[2020-12-03 02:35:44,199 INFO] Step 7400/50000; acc:  31.68; ppl: 155.72; xent: 5.05; lr: 0.10000; 8624/9482 tok/s;    838 sec\n",
            "[2020-12-03 02:35:49,675 INFO] Step 7450/50000; acc:  32.61; ppl: 143.91; xent: 4.97; lr: 0.10000; 9005/9915 tok/s;    843 sec\n",
            "[2020-12-03 02:35:54,993 INFO] Step 7500/50000; acc:  32.36; ppl: 141.51; xent: 4.95; lr: 0.10000; 8929/9951 tok/s;    848 sec\n",
            "[2020-12-03 02:36:00,822 INFO] Step 7550/50000; acc:  31.09; ppl: 155.84; xent: 5.05; lr: 0.10000; 8846/9768 tok/s;    854 sec\n",
            "[2020-12-03 02:36:06,313 INFO] Step 7600/50000; acc:  31.51; ppl: 157.28; xent: 5.06; lr: 0.10000; 8809/9517 tok/s;    860 sec\n",
            "[2020-12-03 02:36:11,556 INFO] Step 7650/50000; acc:  31.92; ppl: 151.97; xent: 5.02; lr: 0.10000; 8881/9584 tok/s;    865 sec\n",
            "[2020-12-03 02:36:17,594 INFO] Step 7700/50000; acc:  31.46; ppl: 152.39; xent: 5.03; lr: 0.10000; 8862/9654 tok/s;    871 sec\n",
            "[2020-12-03 02:36:22,481 INFO] Step 7750/50000; acc:  33.32; ppl: 127.24; xent: 4.85; lr: 0.10000; 8429/9722 tok/s;    876 sec\n",
            "[2020-12-03 02:36:28,323 INFO] Step 7800/50000; acc:  31.83; ppl: 153.59; xent: 5.03; lr: 0.10000; 8927/9697 tok/s;    882 sec\n",
            "[2020-12-03 02:36:32,907 INFO] Step 7850/50000; acc:  33.74; ppl: 127.38; xent: 4.85; lr: 0.10000; 8267/9318 tok/s;    886 sec\n",
            "[2020-12-03 02:36:38,447 INFO] Step 7900/50000; acc:  33.06; ppl: 145.42; xent: 4.98; lr: 0.10000; 9045/9681 tok/s;    892 sec\n",
            "[2020-12-03 02:36:43,719 INFO] Step 7950/50000; acc:  33.30; ppl: 131.25; xent: 4.88; lr: 0.10000; 8595/9614 tok/s;    897 sec\n",
            "[2020-12-03 02:36:48,808 INFO] Step 8000/50000; acc:  33.83; ppl: 127.22; xent: 4.85; lr: 0.10000; 8939/9767 tok/s;    902 sec\n",
            "[2020-12-03 02:36:54,476 INFO] Step 8050/50000; acc:  32.72; ppl: 138.36; xent: 4.93; lr: 0.10000; 9044/10001 tok/s;    908 sec\n",
            "[2020-12-03 02:37:00,038 INFO] Step 8100/50000; acc:  33.01; ppl: 133.92; xent: 4.90; lr: 0.10000; 8880/9754 tok/s;    913 sec\n",
            "[2020-12-03 02:37:05,509 INFO] Step 8150/50000; acc:  32.87; ppl: 131.59; xent: 4.88; lr: 0.10000; 8538/9687 tok/s;    919 sec\n",
            "[2020-12-03 02:37:10,903 INFO] Step 8200/50000; acc:  33.38; ppl: 127.52; xent: 4.85; lr: 0.10000; 8697/9820 tok/s;    924 sec\n",
            "[2020-12-03 02:37:16,255 INFO] Step 8250/50000; acc:  33.12; ppl: 123.13; xent: 4.81; lr: 0.10000; 8443/9665 tok/s;    930 sec\n",
            "[2020-12-03 02:37:22,346 INFO] Step 8300/50000; acc:  32.44; ppl: 131.75; xent: 4.88; lr: 0.10000; 8724/9834 tok/s;    936 sec\n",
            "[2020-12-03 02:37:28,347 INFO] Step 8350/50000; acc:  32.05; ppl: 140.66; xent: 4.95; lr: 0.10000; 8613/9691 tok/s;    942 sec\n",
            "[2020-12-03 02:37:33,785 INFO] Step 8400/50000; acc:  34.21; ppl: 121.68; xent: 4.80; lr: 0.10000; 8882/9778 tok/s;    947 sec\n",
            "[2020-12-03 02:37:36,807 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2020-12-03 02:37:38,750 INFO] number of examples: 77039\n",
            "[2020-12-03 02:37:42,545 INFO] Step 8450/50000; acc:  31.63; ppl: 150.92; xent: 5.02; lr: 0.10000; 6593/7117 tok/s;    956 sec\n",
            "[2020-12-03 02:37:48,722 INFO] Step 8500/50000; acc:  30.95; ppl: 151.16; xent: 5.02; lr: 0.10000; 8876/9705 tok/s;    962 sec\n",
            "[2020-12-03 02:37:54,572 INFO] Step 8550/50000; acc:  34.12; ppl: 130.46; xent: 4.87; lr: 0.10000; 9274/9948 tok/s;    968 sec\n",
            "[2020-12-03 02:38:00,153 INFO] Step 8600/50000; acc:  33.48; ppl: 132.24; xent: 4.88; lr: 0.10000; 8679/9494 tok/s;    974 sec\n",
            "[2020-12-03 02:38:05,406 INFO] Step 8650/50000; acc:  35.44; ppl: 112.41; xent: 4.72; lr: 0.10000; 8984/9922 tok/s;    979 sec\n",
            "[2020-12-03 02:38:10,705 INFO] Step 8700/50000; acc:  34.34; ppl: 118.03; xent: 4.77; lr: 0.10000; 8901/9974 tok/s;    984 sec\n",
            "[2020-12-03 02:38:16,661 INFO] Step 8750/50000; acc:  33.68; ppl: 127.09; xent: 4.84; lr: 0.10000; 8980/9742 tok/s;    990 sec\n",
            "[2020-12-03 02:38:22,043 INFO] Step 8800/50000; acc:  33.94; ppl: 125.41; xent: 4.83; lr: 0.10000; 8845/9707 tok/s;    995 sec\n",
            "[2020-12-03 02:38:27,270 INFO] Step 8850/50000; acc:  34.25; ppl: 124.49; xent: 4.82; lr: 0.10000; 8686/9391 tok/s;   1001 sec\n",
            "[2020-12-03 02:38:33,489 INFO] Step 8900/50000; acc:  33.41; ppl: 126.89; xent: 4.84; lr: 0.10000; 8957/9795 tok/s;   1007 sec\n",
            "[2020-12-03 02:38:38,383 INFO] Step 8950/50000; acc:  35.12; ppl: 107.91; xent: 4.68; lr: 0.10000; 8307/9539 tok/s;   1012 sec\n",
            "[2020-12-03 02:38:44,054 INFO] Step 9000/50000; acc:  34.13; ppl: 123.95; xent: 4.82; lr: 0.10000; 8906/9719 tok/s;   1017 sec\n",
            "[2020-12-03 02:38:48,704 INFO] Step 9050/50000; acc:  35.60; ppl: 104.76; xent: 4.65; lr: 0.10000; 8160/9288 tok/s;   1022 sec\n",
            "[2020-12-03 02:38:54,275 INFO] Step 9100/50000; acc:  34.86; ppl: 124.14; xent: 4.82; lr: 0.10000; 9247/9763 tok/s;   1028 sec\n",
            "[2020-12-03 02:38:59,583 INFO] Step 9150/50000; acc:  35.57; ppl: 108.63; xent: 4.69; lr: 0.10000; 8621/9609 tok/s;   1033 sec\n",
            "[2020-12-03 02:39:04,737 INFO] Step 9200/50000; acc:  35.88; ppl: 105.02; xent: 4.65; lr: 0.10000; 9037/9874 tok/s;   1038 sec\n",
            "[2020-12-03 02:39:10,385 INFO] Step 9250/50000; acc:  34.79; ppl: 114.22; xent: 4.74; lr: 0.10000; 8974/9969 tok/s;   1044 sec\n",
            "[2020-12-03 02:39:15,847 INFO] Step 9300/50000; acc:  35.29; ppl: 110.11; xent: 4.70; lr: 0.10000; 8772/9623 tok/s;   1049 sec\n",
            "[2020-12-03 02:39:21,279 INFO] Step 9350/50000; acc:  35.00; ppl: 109.23; xent: 4.69; lr: 0.10000; 8529/9623 tok/s;   1055 sec\n",
            "[2020-12-03 02:39:26,743 INFO] Step 9400/50000; acc:  34.93; ppl: 110.16; xent: 4.70; lr: 0.10000; 8762/9888 tok/s;   1060 sec\n",
            "[2020-12-03 02:39:32,108 INFO] Step 9450/50000; acc:  35.20; ppl: 103.65; xent: 4.64; lr: 0.10000; 8399/9612 tok/s;   1065 sec\n",
            "[2020-12-03 02:39:38,221 INFO] Step 9500/50000; acc:  34.75; ppl: 109.39; xent: 4.69; lr: 0.10000; 8776/9890 tok/s;   1072 sec\n",
            "[2020-12-03 02:39:44,221 INFO] Step 9550/50000; acc:  34.22; ppl: 115.66; xent: 4.75; lr: 0.10000; 8421/9530 tok/s;   1078 sec\n",
            "[2020-12-03 02:39:49,673 INFO] Step 9600/50000; acc:  36.22; ppl: 99.49; xent: 4.60; lr: 0.10000; 8812/9749 tok/s;   1083 sec\n",
            "[2020-12-03 02:39:53,235 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2020-12-03 02:39:55,473 INFO] number of examples: 77039\n",
            "[2020-12-03 02:39:58,556 INFO] Step 9650/50000; acc:  34.00; ppl: 122.62; xent: 4.81; lr: 0.10000; 6304/6822 tok/s;   1092 sec\n",
            "[2020-12-03 02:40:04,845 INFO] Step 9700/50000; acc:  32.75; ppl: 129.62; xent: 4.86; lr: 0.10000; 8811/9666 tok/s;   1098 sec\n",
            "[2020-12-03 02:40:10,963 INFO] Step 9750/50000; acc:  35.54; ppl: 115.78; xent: 4.75; lr: 0.10000; 9319/9812 tok/s;   1104 sec\n",
            "[2020-12-03 02:40:16,483 INFO] Step 9800/50000; acc:  35.49; ppl: 110.09; xent: 4.70; lr: 0.10000; 8522/9445 tok/s;   1110 sec\n",
            "[2020-12-03 02:40:21,716 INFO] Step 9850/50000; acc:  37.36; ppl: 92.82; xent: 4.53; lr: 0.10000; 8823/9789 tok/s;   1115 sec\n",
            "[2020-12-03 02:40:27,268 INFO] Step 9900/50000; acc:  36.15; ppl: 102.04; xent: 4.63; lr: 0.10000; 8980/9979 tok/s;   1121 sec\n",
            "[2020-12-03 02:40:33,087 INFO] Step 9950/50000; acc:  35.84; ppl: 105.50; xent: 4.66; lr: 0.10000; 9027/9800 tok/s;   1126 sec\n",
            "[2020-12-03 02:40:38,412 INFO] Step 10000/50000; acc:  35.93; ppl: 103.90; xent: 4.64; lr: 0.10000; 8819/9674 tok/s;   1132 sec\n",
            "[2020-12-03 02:40:38,412 INFO] Loading dataset from OpenNMT-py/data/demo.valid.0.pt\n",
            "[2020-12-03 02:40:38,593 INFO] number of examples: 9986\n",
            "Traceback (most recent call last):\n",
            "  File \"OpenNMT-py/train.py\", line 6, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/bin/train.py\", line 197, in main\n",
            "    train(opt)\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/bin/train.py\", line 95, in train\n",
            "    single_main(opt, 0)\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/train_single.py\", line 150, in main\n",
            "    valid_steps=opt.valid_steps)\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/trainer.py\", line 280, in train\n",
            "    valid_iter, moving_average=self.moving_average)\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/trainer.py\", line 340, in validate\n",
            "    with_align=self.with_align)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/models/model.py\", line 45, in forward\n",
            "    enc_state, memory_bank, lengths = self.encoder(src, lengths)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/encoders/rnn_encoder.py\", line 74, in forward\n",
            "    packed_emb = pack(emb, lengths_list)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/utils/rnn.py\", line 244, in pack_padded_sequence\n",
            "    _VF._pack_padded_sequence(input, lengths, batch_first)\n",
            "RuntimeError: Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLSDUzUa4mdu",
        "outputId": "8653e9c3-1290-433e-a860-57d22613bf7a"
      },
      "source": [
        "!python OpenNMT-py/translate.py -model demo-model_step_45000.pt -src OpenNMT-py/data/tedtalksal_es_test.txt -output OpenNMT-py/data/pred.txt -replace_unk -verbose -beam_size 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-12-01 01:23:35,582 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:52: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: OrderedIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "[2020-12-01 01:23:35,808 INFO] \n",
            "SENT 1: ['No', 'solo', 'sucede', 'alli,', 'tambien', 'en', 'dietas', 'naturales', 'de', 'algunas', 'comunidades', 'en', 'el', 'artico', 'canadiense', 'y', 'el', 'de', 'los', 'EUA', 'y', 'en', 'el', 'artico', 'europeo,', 'una', 'dieta', 'natural', 'de', 'leones', 'marinos', 'y', 'ballenas', 'conlleva', 'a', 'la', 'acumulación', 'de', 'PCB', 'que', 'han', 'acarreado', 'de', 'todas', 'partes', 'del', 'mundo', 'y', 'terminan', 'en', 'éstas', 'mujeres.']\n",
            "PRED 1: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,809 INFO] \n",
            "SENT 2: ['Ésta', 'es', 'la', 'África', 'de', 'la', 'oportunidad.']\n",
            "PRED 2: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,809 INFO] \n",
            "SENT 3: ['Y', 'los', 'mataron,', 'utilizaron', 'la', 'grasa', 'durante', 'el', 'invierno', 'para', 'cocinar.']\n",
            "PRED 3: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,809 INFO] \n",
            "SENT 4: ['Su', 'propagación', 'ha', 'sido', 'lenta.']\n",
            "PRED 4: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,809 INFO] \n",
            "SENT 5: ['HC:', 'De', 'esto', 'no', 'tenemos', 'antecedentes', 'culinarios.', 'Es', 'un', 'cigarro,', 'un', 'puro', 'cubano', 'hecho', 'con', 'un', 'sándwich', 'cubano', 'de', 'cerdo,', 'así', 'que', 'tomamos', 'las', 'especias', 'que', 'van', 'en', 'el', 'lomo', 'del', 'cerdo', 'les', 'damos', 'forma', 'de', 'ceniza.', 'Tomamos', 'el', 'sándwich', 'y', 'lo', 'envolvemos', 'en', 'una', 'col', 'verde,', 'le', 'ponemos', 'una', 'etiqueta', 'comestible', 'que', 'no', 'guarda', 'ninguna', 'similitud', 'con', 'una', 'etiqueta', 'de', 'Cohiba,', 'lo', 'ponemos', 'en', 'un', 'cenicero', 'de', 'US$1,99', 'y', 'cobramos', 'unos', 'US$20', 'por', 'el', 'mismo.']\n",
            "PRED 5: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,809 INFO] \n",
            "SENT 6: ['Está', 'el', 'pueblo,', 'y', 'luego', 'están', 'los', 'gobiernos', 'o', 'líderes.']\n",
            "PRED 6: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,810 INFO] \n",
            "SENT 7: ['y', 'a', 'partir', 'de', 'su', 'esfuerzo', 'con', 'el', 'apoyo', 'ejemplar', 'de', 'su', 'madre,', 'de', 'su', 'familia', 'y', 'de', 'su', 'pueblo', 'ha', 'llegado', 'a', 'ser', 'miembro', 'principal', 'de', 'la', 'fila', 'de', 'contrabajos', 'de', 'la', 'Filarmónica', 'de', 'Berlin']\n",
            "PRED 7: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,810 INFO] \n",
            "SENT 8: ['Las', 'abejas', 'no', 'son', 'nativas', 'de', 'América;', 'fueron', 'introducidas', 'con', 'los', 'colonos.']\n",
            "PRED 8: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,810 INFO] \n",
            "SENT 9: ['Las', 'religiones', 'combinan', 'ambas', 'cosas', 'de', 'manera', 'fascinante.']\n",
            "PRED 9: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,810 INFO] \n",
            "SENT 10: ['Esto', 'fue', 'descubierto', 'en', '1859.']\n",
            "PRED 10: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,810 INFO] \n",
            "SENT 11: ['Son', 'relojes', 'químicos', 'y', 'están', 'en', 'todos', 'los', 'seres', 'conocidos', 'que', 'tienen', '2', 'o', 'más', 'células', 'y', 'en', 'algunos', 'unicelulares.']\n",
            "PRED 11: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,810 INFO] \n",
            "SENT 12: ['Es', 'un', 'pollo', 'de', 'aspecto', 'más', 'moderno.']\n",
            "PRED 12: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,811 INFO] \n",
            "SENT 13: ['Aquí', 'hay', 'un', 'mapa.', 'Todo', 'lo', 'que', 'tienen', 'es', 'un', 'casino.']\n",
            "PRED 13: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,811 INFO] \n",
            "SENT 14: ['Y', 'a', 'los', 'gansos', 'les', 'encanta', 'el', 'altramuz.']\n",
            "PRED 14: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,811 INFO] \n",
            "SENT 15: ['La', 'canción', 'es', 'una', 'de', 'las', 'formas', 'más', 'viejas', 'de', 'hacernos', 'escuchar', 'y', 'entender.']\n",
            "PRED 15: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,811 INFO] \n",
            "SENT 16: ['Y', 'hago', 'que', 'conversen', 'durante', 'unos', '10', 'segundos', 'y', 'luego', 'grito:', '\"¡Descanso!\"']\n",
            "PRED 16: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,811 INFO] \n",
            "SENT 17: ['¿Cinco', 'minutos,', 'en', 'lugar', 'de', 'ver', 'la', 'TV?']\n",
            "PRED 17: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,812 INFO] \n",
            "SENT 18: ['Este', 'es', 'el', 'sistema', 'central,']\n",
            "PRED 18: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,812 INFO] \n",
            "SENT 19: ['Este', 'es', 'quien,', 'puede', 'ver', 'justo', 'sobre', 'su', 'hombro', 'derecho,', 'él', 'es', 'quien', 'cazó', 'al', 'mono', 'de', 'la', 'última', 'foto', 'que', 'les', 'mostré.']\n",
            "PRED 19: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,812 INFO] \n",
            "SENT 20: ['Y', 'luego,', 'cuando', 'llegaban', 'a', 'una', 'parada,', 'el', 'joven', 'hacía', 'un', 'repentino', 'despegue', 'vertical,', 'de', '30', 'metros', 'en', 'el', 'aire,', 'y', 'luego', 'desaparecía.']\n",
            "PRED 20: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,812 INFO] \n",
            "SENT 21: ['Ahora', 'mi', 'objetivo', 'es', 'la', 'funcionalidad', 'emocional', 'de', 'las', 'cosas.']\n",
            "PRED 21: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,812 INFO] \n",
            "SENT 22: ['Esto', 'va', 'más', 'allá', 'de', 'cualquier', 'cosa', 'que', 'pudiera', 'inventar', 'cualquiera.']\n",
            "PRED 22: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,812 INFO] \n",
            "SENT 23: ['Imaginen', 'lo', 'vulnerable', 'que', 'es', 'el', 'sistema', 'a', 'ataques', 'deliberados.']\n",
            "PRED 23: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,813 INFO] \n",
            "SENT 24: ['Y', 'si', 'bien', 'ahora', 'estoy', 'bien,', 'no', 'les', 'deseo', 'este', 'regalo.']\n",
            "PRED 24: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,813 INFO] \n",
            "SENT 25: ['Y', 'me', 'hizo', 'recordar.']\n",
            "PRED 25: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,813 INFO] \n",
            "SENT 26: ['Pero', 'estoy', 'realmente', 'esperanzada.']\n",
            "PRED 26: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,813 INFO] \n",
            "SENT 27: ['Más', 'grano', 'en', 'un', 'par', 'de', 'semanas', 'del', 'que', 'se', 'comería', 'en', 'toda', 'su', 'vida.']\n",
            "PRED 27: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,813 INFO] \n",
            "SENT 28: ['Creo', 'que', 'podemos', 'usar', 'nuestra', 'tecnología', 'para', 'digitalizar', 'cosas', '--', 'ponerlas', 'en', 'la', 'red', 'para', 'después', 'descargarlas,', 'imprimirlas', 'y', 'encuadernarlas,', 'y', 'terminar', 'así', 'de', 'nuevo', 'con', 'un', 'libro']\n",
            "PRED 28: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,813 INFO] \n",
            "SENT 29: ['AB:', '¿No', 'mencionó', 'el', 'número', '7?']\n",
            "PRED 29: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,814 INFO] \n",
            "SENT 30: ['Ahí', 'es', 'cuando', 'empieza', 'el', 'amor;', 'cuando', 'empieza', 'la', 'estructura.']\n",
            "PRED 30: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,930 INFO] \n",
            "SENT 31: ['De', 'modo', 'que', 'salimos', 'a', 'buscar', 'compañías.']\n",
            "PRED 31: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,931 INFO] \n",
            "SENT 32: ['Y', 'creo', 'que', 'a', 'menudo,', 'la', 'gente', 'se', 'pierde', 'en', 'eso.']\n",
            "PRED 32: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,931 INFO] \n",
            "SENT 33: ['<No,', 'no,', 'en', 'serio,', 'estoy', 'suficientemente', 'liada', 'con', 'las', 'estrellas.']\n",
            "PRED 33: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,931 INFO] \n",
            "SENT 34: ['Se', 'levantan', 'un', 'poquito', 'más', 'tarde', 'todos', 'los', 'días,', 'unos', '15', 'minutos,', 'y', 'se', 'desvían', 'de', 'su', 'ciclo', 'biológico', 'durante', 'semanas.']\n",
            "PRED 34: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,931 INFO] \n",
            "SENT 35: ['Bueno,', 'ahora', 'traje', 'esto', 'frente', 'a', 'él.']\n",
            "PRED 35: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,931 INFO] \n",
            "SENT 36: ['¿Por', 'qué?']\n",
            "PRED 36: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,932 INFO] \n",
            "SENT 37: ['Ahora', 'tenemos', 'suburbios', 'residenciales', 'dispersos', 'que', 'son', 'bien', 'distintos', 'de', 'las', 'áreas', 'de', 'producción', 'y', 'áreas', 'comerciales.']\n",
            "PRED 37: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,932 INFO] \n",
            "SENT 38: ['¿Cuándo', 'empieza', 'el', 'proceso', 'de', 'aprendizaje?', '¿empieza', 'en', 'primer', 'grado?']\n",
            "PRED 38: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,932 INFO] \n",
            "SENT 39: ['Es', 'así', 'que', 'ahora', 'en', 'esa', 'página', 'Web', 'tenemos', '18000', 'personas;']\n",
            "PRED 39: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,932 INFO] \n",
            "SENT 40: ['Él', 'considera', 'el', 'juego', 'como', 'la', 'fuerza', 'de', 'transformación', 'de', 'su', 'vida', 'entera.']\n",
            "PRED 40: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,932 INFO] \n",
            "SENT 41: ['Vivimos', 'en', 'un', 'tiempo', 'notable:', 'la', 'era', 'de', 'la', 'genómica.']\n",
            "PRED 41: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,933 INFO] \n",
            "SENT 42: ['Y', 'sólo', 'para', 'darles', 'una', 'idea', 'han', 'gastando', '20', 'millones', 'en', '20', 'años.']\n",
            "PRED 42: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,933 INFO] \n",
            "SENT 43: ['El', 'dilema', 'del', 'prisionero', 'es,', 'en', 'realidad,', 'una', 'historia', 'de', 'el', 'modelo', 'matemático', 'de', 'la', 'teoría', 'del', 'juego', 'cuando', 'se', 'comenzó', 'a', 'reflexionar', 'sobre', 'la', 'guerra', 'nuclear:', 'dos', 'jugadores', 'que', 'no', 'podían', 'confiar', 'uno', 'en', 'el', 'otro.']\n",
            "PRED 43: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,933 INFO] \n",
            "SENT 44: ['\"A', 'veces,\"', 'me', 'decía,', '\"antes', 'de', 'que', 'llegara', 'la', 'gente', 'tenía', 'alucinaciones', 'con', 'cuadrados', 'rosa', 'y', 'azul', 'en', 'el', 'suelo,', 'que', 'parecían', 'ir', 'hasta', 'el', 'techo.\"']\n",
            "PRED 44: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,933 INFO] \n",
            "SENT 45: ['Y', 'sí,', 'ellos', 'fueron', 'grandes', 'filántropos']\n",
            "PRED 45: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,933 INFO] \n",
            "SENT 46: ['Me', 'preguntó', 'si', 'podría', 'escuchar', 'mi', '\"música', 'tribal\"', 'y', 'se', 'mostró', 'por', 'tanto', 'muy', 'decepcionada', 'cuando', 'le', 'mostré', 'mi', 'cinta', 'de', 'Mariah', 'Carey.']\n",
            "PRED 46: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,933 INFO] \n",
            "SENT 47: ['El', 'pollo', 'es', 'un', 'dinosaurio.']\n",
            "PRED 47: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,934 INFO] \n",
            "SENT 48: ['Si', 'no', 'desarrollamos', 'la', 'estámina', 'de', 'aferrarnos', 'a', 'las', 'cosas', '--', 'lo', 'que', 'sea', 'que', 'escojas,', 'mantente', 'en', 'ello', '--', 'sino', 'como', 'ustedes', 'saben,', 'todo', 'va', 'a', 'ser', 'un', 'capricho', 'pasajero.']\n",
            "PRED 48: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,934 INFO] \n",
            "SENT 49: ['Pues', 'él', 'no.']\n",
            "PRED 49: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,934 INFO] \n",
            "SENT 50: ['Así', 'como', 'los', 'pilotos', 'de', 'carrera', 'usan', 'toda', 'la', 'fricción', 'entre', 'el', 'neumático', 'y', 'la', 'pista,', 'todos', 'los', 'recursos', 'del', 'coche', 'para', 'ir', 'lo', 'más', 'rápido', 'posible,', 'queremos', 'usar', 'esos', 'recursos', 'para', 'evitar', 'todos', 'los', 'accidentes', 'que', 'podamos.']\n",
            "PRED 50: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,934 INFO] \n",
            "SENT 51: ['Pero', 'si', 'leemos', 'los', 'enlaces', 'es', 'muy', 'notable.']\n",
            "PRED 51: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,934 INFO] \n",
            "SENT 52: ['Y', 'esto', 'es', 'lo', 'que', 'empezamos', 'a', 'hacer', 'en', 'uno', 'de', 'los', 'países', 'más', 'grandes', 'del', 'continente,', 'Nigeria.']\n",
            "PRED 52: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,935 INFO] \n",
            "SENT 53: ['Sólo', 'quiero', 'mostrarles', 'un', 'diagrama', 'técnico', 'aquí.']\n",
            "PRED 53: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,935 INFO] \n",
            "SENT 54: ['$55.000.', 'Y', 'es', 'una', 'oferta', 'increíble.']\n",
            "PRED 54: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,935 INFO] \n",
            "SENT 55: ['Dicen', 'que', 'las', 'personas', 'que', 'realizan', 'muchas', 'actividades', 'son', 'más', 'felices,', 'que', 'es', 'más', 'fácil', 'cuidarlas', 'y', 'que', 'esto', 'incluso', 'puede', 'ralentizar', 'el', 'avance', 'de', 'la', 'enfermedad.']\n",
            "PRED 55: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,935 INFO] \n",
            "SENT 56: ['Quiero', 'pedirles', 'que', 'consideren', 'por', 'un', 'segundo', 'el', 'hecho', 'muy', 'simple', 'de', 'que,', 'por', 'lejos,', 'gran', 'parte', 'de', 'lo', 'que', 'sabemos', 'del', 'Universo', 'proviene', 'de', 'la', 'luz.']\n",
            "PRED 56: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,935 INFO] \n",
            "SENT 57: ['Y', 'él', 'está', 'controlando', 'el', 'movimiento', 'de', 'las', 'orejas.']\n",
            "PRED 57: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,936 INFO] \n",
            "SENT 58: ['La', 'segunda', 'es', 'hospital.', 'Y', 'la', 'tercera', 'es', 'enfermedad', 'o', 'enfermo,', '¿verdad?']\n",
            "PRED 58: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,936 INFO] \n",
            "SENT 59: ['\"¡Miren!', 'Una', 'sirena', 'saliendo', 'del', 'pantano.', '¡Vaya!']\n",
            "PRED 59: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "[2020-12-01 01:23:35,936 INFO] \n",
            "SENT 60: ['Es', 'tan', 'fácil', 'como', 'pescar', 'en', 'un', 'estanque.']\n",
            "PRED 60: es\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"OpenNMT-py/translate.py\", line 6, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/bin/translate.py\", line 48, in main\n",
            "    translate(opt)\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/bin/translate.py\", line 32, in translate\n",
            "    align_debug=opt.align_debug\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/translate/translator.py\", line 362, in translate\n",
            "    batch, data.src_vocabs, attn_debug\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/translate/translator.py\", line 551, in translate_batch\n",
            "    decode_strategy)\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/translate/translator.py\", line 648, in _translate_batch_with_strategy\n",
            "    src, enc_states, memory_bank, src_lengths = self._run_encoder(batch)\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/translate/translator.py\", line 558, in _run_encoder\n",
            "    src, src_lengths)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/My Drive/NLP_Project_Personal/OpenNMT-py/onmt/encoders/rnn_encoder.py\", line 74, in forward\n",
            "    packed_emb = pack(emb, lengths_list)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/utils/rnn.py\", line 244, in pack_padded_sequence\n",
            "    _VF._pack_padded_sequence(input, lengths, batch_first)\n",
            "RuntimeError: Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFDEPIyK5ULS"
      },
      "source": [
        "/content/drive/MyDrive/NLP_Project_Personal/demo-model_step_45000.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1qNRhZwLlfj"
      },
      "source": [
        "sed -i \"s/@@ //g\"  OpenNMT-py/data/pred.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfoQAegDLmp-"
      },
      "source": [
        "perl  OpenNMT-py/tools/multi-bleu.perl OpenNMT-py/data/ref.txt < OpenNMT-py/data/pred.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgDbspsbMIaI"
      },
      "source": [
        ""
      ]
    }
  ]
}